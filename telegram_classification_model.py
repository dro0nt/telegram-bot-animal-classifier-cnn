import io
import logging
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from PIL import Image

from telegram import Update
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
MODEL_PATH = 'cub_birds_classifier_model.keras'
CLASS_NAMES_PATH = 'class_names.txt'
IMG_SIZE = (224, 224)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –∫–ª–∞—Å—Å–æ–≤
model = tf.keras.models.load_model(MODEL_PATH)
with open(CLASS_NAMES_PATH, 'r', encoding='utf-8') as f:
    class_names = [line.strip() for line in f.readlines()]

def preprocess_image(image: Image.Image):
    image = image.resize(IMG_SIZE)
    img_array = tf.keras.preprocessing.image.img_to_array(image)
    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)
    return tf.expand_dims(img_array, axis=0)

def plot_top_predictions(image: Image.Image, preds, top=5):
    top_indices = np.argsort(preds[0])[::-1][:top]
    top_probs = preds[0][top_indices]
    top_labels = [class_names[i] for i in top_indices]

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))
    ax1.imshow(image)
    ax1.axis('off')
    ax1.set_title("–ü—Ä–∏—Å–ª–∞–Ω–Ω–æ–µ —Ñ–æ—Ç–æ")

    ax2.barh(range(top), top_probs[::-1], color='skyblue')
    ax2.set_yticks(range(top))
    ax2.set_yticklabels(top_labels[::-1])
    ax2.invert_yaxis()
    ax2.set_xlabel("–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å")
    ax2.set_title("–¢–æ–ø-5 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")

    buf = io.BytesIO()
    plt.tight_layout()
    plt.savefig(buf, format='png')
    buf.seek(0)
    plt.close(fig)
    return buf

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø ‚Äî –±–æ—Ç, –æ–±—É—á–µ–Ω–Ω—ã–π —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å 200 –≤–∏–¥–æ–≤ –ø—Ç–∏—Ü –ø–æ —Ñ–æ—Ç–æ üê¶\n\n"
        "üì∏ –ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å –º–Ω–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –ø—Ç–∏—Ü—ã ‚Äî —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –µ—ë –≤–∏–¥ –∏ –ø–æ–∫–∞–∂—É –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã.\n\n"
        "‚ùì –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –∫–æ–º–∞–Ω–¥ ‚Äî –≤–≤–µ–¥–∏ /help.\n\n"
        "üîç –û–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ: –±–æ—Ç –æ–±—É—á–µ–Ω –Ω–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö, –ø–æ—ç—Ç–æ–º—É –º–æ–∂–µ—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ–¥–∫–∏–µ –∏–ª–∏ —ç–∫–∑–æ—Ç–∏—á–µ—Å–∫–∏–µ –≤–∏–¥—ã."
    )

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    help_text = (
        "–ö–æ–º–∞–Ω–¥—ã –±–æ—Ç–∞:\n"
        "/start - –Ω–∞—á–∞—Ç—å –æ–±—â–µ–Ω–∏–µ\n"
        "/help - –ø–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ\n"
        "/classes - –ø–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –≤–∏–¥–æ–≤ –ø—Ç–∏—Ü\n"
        "–ü—Ä–æ—Å—Ç–æ –ø—Ä–∏—à–ª–∏ —Ñ–æ—Ç–æ –ø—Ç–∏—Ü—ã –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è."
    )
    await update.message.reply_text(help_text)

async def classes_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chunk_size = 50
    total = len(class_names)
    chunks = [class_names[i:i + chunk_size] for i in range(0, total, chunk_size)]

    for i, chunk in enumerate(chunks):
        text = f"–°–ø–∏—Å–æ–∫ –ø—Ç–∏—Ü ({i*chunk_size+1}-{i*chunk_size+len(chunk)} –∏–∑ {total}):\n"
        text += '\n'.join(chunk)
        await update.message.reply_text(text)

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        photo = update.message.photo[-1]
        photo_file = await photo.get_file()
        byte_array = await photo_file.download_as_bytearray()
        image = Image.open(io.BytesIO(byte_array)).convert('RGB')

        input_tensor = preprocess_image(image)
        preds = model.predict(input_tensor)

        top_index = preds[0].argmax()
        top_class = class_names[top_index]
        top_prob = preds[0][top_index]

        result_buf = plot_top_predictions(image, preds)

        caption_text = f"–Ø –¥—É–º–∞—é, —á—Ç–æ —ç—Ç–æ ‚Äî {top_class}.\n–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {top_prob:.2%}"

        await update.message.reply_photo(photo=result_buf, caption=caption_text)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–æ—Ç–æ: {e}")
        await update.message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

async def handle_non_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–∏—à–ª–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –ø—Ç–∏—Ü—ã –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.")

def main():
    TOKEN = 'TOKEN'  # <-- –ó–∞–º–µ–Ω–∏ –Ω–∞ —Å–≤–æ–π —Ç–æ–∫–µ–Ω
    app = ApplicationBuilder().token(TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CommandHandler("classes", classes_command))
    app.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    app.add_handler(MessageHandler(~filters.PHOTO, handle_non_photo))  # –í—Å—ë, —á—Ç–æ –Ω–µ —Ñ–æ—Ç–æ

    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
    app.run_polling()

if __name__ == '__main__':
    main()